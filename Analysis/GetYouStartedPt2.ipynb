{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Trips Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dir\n",
    "data_dir = \"Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trips_25_9.csv_processed.csv',\n",
       " 'travelers.xlsx',\n",
       " 'trips_23_9.csv_processed.csv',\n",
       " 'trips_26_9.csv_processed.csv',\n",
       " 'trips_21_9.csv_processed.csv',\n",
       " 'trips_20_9.csv_processed.csv',\n",
       " 'satisfaction.csv',\n",
       " 'trips_22_9.csv_processed.csv',\n",
       " 'incidents.csv',\n",
       " 'trips_24_9.csv_processed.csv',\n",
       " 'Data_Description.docx',\n",
       " 'stations.csv',\n",
       " 'stops.csv',\n",
       " 'facilities.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the infrabel trip files\n",
    "all_trips = [obs for obs in os.listdir(data_dir) if \".DS\" not in obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_trips = pd.DataFrame()\n",
    "print(full_trips.shape)\n",
    "\n",
    "for trip in all_trips:\n",
    "    # import \n",
    "    df = pd.read_csv(os.path.join(data_dir, trip), sep=\",\")\n",
    "    full_trips = full_trips.append(df)\n",
    "    print(full_trips.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import facilities\n",
    "facilities = pd.read_csv(\"../data/facilities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "facilities.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of missing values per variable\n",
    "for col in facilities.columns:\n",
    "    missings = len(facilities[col][facilities[col].isnull()]) / float(len(facilities))\n",
    "    print(col, missings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data type of columns\n",
    "facilities.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facilities['sales_open_monday2'] = pd.to_datetime(facilities['sales_open_monday'].astype(str), format='%H:%M')-pd.to_datetime('00:00', format='%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see new column is of type timedelta64\n",
    "facilities.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for instance only use subset of 'late openers'\n",
    "late_openers = facilities[facilities['sales_open_monday2'] > pd.Timedelta(8,'h')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_openers['sales_open_monday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use it to impute missing values\n",
    "facilities['sales_open_monday2'].fillna((facilities['sales_open_monday2'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of missing values per variable\n",
    "for col in facilities.columns:\n",
    "    missings = len(facilities[col][facilities[col].isnull()]) / float(len(facilities))\n",
    "    print(col, missings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travelers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "travelers = pd.read_excel(\"../data/travelers.xlsx\", header=1, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check\n",
    "travelers.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "travelers = travelers.rename({\"Avg number of travelers in the week\": \"week\",\n",
    "                              \"Avg number of travelers on Saturday\": \"saturday\",\n",
    "                              \"Avg number of travelers on Sunday\": \"sunday\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of missing values per variable\n",
    "for col in travelers.columns:\n",
    "    missings = len(travelers[col][travelers[col].isnull()]) / float(len(travelers))\n",
    "    print(col, missings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missings\n",
    "# change settings to visualize ALL rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(travelers[travelers.isnull().any(axis=1)])\n",
    "\n",
    "# change settings back\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting: never completely missing\n",
    "# Inspection Wikipedia and NMBS website revealed no train rides on these dates for these stations (e.g., Baasrode-Zuid & Buda only train rides during the week)\n",
    "# Therefore we impute every missing value with zero\n",
    "\n",
    "travelers['week'].fillna(0, inplace=True)\n",
    "travelers['saturday'].fillna(0, inplace=True)\n",
    "travelers['sunday'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create total\n",
    "travelers[\"week_total\"] = 5 * travelers[\"week\"] + travelers[\"saturday\"] + travelers[\"sunday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weekend avg\n",
    "travelers[\"weekend\"] = (travelers[\"sunday\"] + travelers[\"saturday\"]) / float(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get avg travelers per day\n",
    "travelers[\"avg_day\"] = travelers[\"week_total\"] / float(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check top 5 stations with highest number of travelers during the weekend\n",
    "travelers.sort_values(by=\"week\", ascending=False)[[\"Station\", \"week\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check top 5 stations with highest number of travelers during the week\n",
    "travelers.sort_values(by=\"weekend\", ascending=False)[[\"Station\", \"weekend\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most remarkable differences are between Brussels Midi and Brussels North. North is in the middle of business centre ==> attracts many commuters during the week while Brussels Midi is the most important international railway station of Belgium and thus attracts many tourists. Also notice how Antwerpen and Leuven almost have equal travellers during the week and are off by almost a factor two during the weekend. This could signify a more or less equal commute potential but a far greater touristic potential for Antwerp. However, both are edjucated guesses based on my personal knowledge about the country. Implementing this mathematical and on a larger scale requires external data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other explanations for the commute numbers may possible lay in the number of facilities. As a proof of concept, let's try to mathematically proof whether weekly commute numbers are linked to availabilty of free parking and/or tram stations nearby. To do so, we will link the facilities and travelers datasets. We will impute missing values of free parking and tram with these facilities not being available. However, do note that this is not necessarily the best assumption!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute columns with zero values\n",
    "facilities['free_parking'].fillna(0, inplace=True)\n",
    "facilities['tram'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travelers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEM: no exact match in traveler/facilities information\n",
    "# ASSUMPTION: travelers is subset of facilities\n",
    "\n",
    "# convert to lower case\n",
    "facilities['name'] = facilities['name'].str.lower()\n",
    "travelers['Station'] =  travelers['Station'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check overlap\n",
    "len(list(set(facilities['name']).intersection(set(travelers['Station']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# around 80 which will need manual imputation\n",
    "intersection = list(set(facilities['name']).intersection(set(travelers['Station'])))\n",
    "\n",
    "still_needed = set(travelers['Station']).difference(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(still_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "still_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facility_names = set(facilities['name']).difference(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "facility_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The facilities dateset also includes international stations, more small stations and different names for the stations with bilingual names or more complicated names. We will have to impute these manually. I will do some, but you will have to create a dictionary of all linked names in order to impute those names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary with correct names\n",
    "Dict = dict({'antwerpen-caal': 'antwerpen-centraal', \n",
    "             'arcades': 'arcaden/arcades', \n",
    "             'beignee':'beignée', \n",
    "             'berchem-st-ag.-berchem':'sint-agatha-berchem/berchem-sainte-agathe'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace names\n",
    "travelers = travelers.replace({\"Station\": Dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if overlap +4 (previously overlap = 473)\n",
    "len(list(set(facilities['name']).intersection(set(travelers['Station']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlap has increased by four. These four are the four stations I have mapped out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we have imputed all station names. Now we can merge the two datasets and run an analysis to see whether tram and free parking availability correlate to the number of travelers on a weekday. Do note that the relationship can be bi-directional. People can be inclined to use stations with connection to trams, but public transport companies can also be more likely to link their network with popular train stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first merge\n",
    "merge = pd.merge(facilities, travelers, left_on='name', right_on='Station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all were matched\n",
    "merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform a multivariate regression, we will use the statsmodels package. Note that sklearn (which you will use later on in the course) also has an implementation of the model. However, sklearn focuses more on predictive performance (how good you can predict something) instead of statistical inference. Since we are interested whether relationships are significant, we will use statsmodels in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run this code once for installation of the package\n",
    "# !pip3 install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# run multivariate regression\n",
    "X = merge[['tram', 'free_parking']]\n",
    "Y = merge['week']\n",
    "X = sm.add_constant(X) # adding a constant: Y = beta0 + beta1*X1 + beta2*X2 + espilon instead of Y = beta1*X1 + beta2*X2 + epsilon\n",
    " \n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results of regression\n",
    "print_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model indicates both tram and free_parking as having a significant positive relationship with the number of weekly travelers, with tram access being of greater influence. The (adjusted) R² of slightly above 0.10 indicates a model which learns some useful relationships, but misses a lot of relevant control variables. However, we did not check the assumptions made by the multivariate linear regression model (e.g., multicollinearity), which could possibly violate the validity of our results. You should do these checks for your group assignment, as well as those for other tests/models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this week's course material, you should be able to solve following subquestions:\n",
    "<br>\n",
    "<br>\n",
    "Q12: Which cities are the worst with regard to access to train facilities? You can do this by calculating the travel distance, travel time, ... Would you recommend based on this, and the visualization in Q5, to create some new routes?\n",
    "<br>\n",
    "<br>\n",
    "Q14: Determine unique facilities that are very rare in orders of prevalence. Infer what may cause these facilities to be in place on their current locations. Are there possible other stations that could benefit from these facilities?\n",
    "<br>\n",
    "<br>\n",
    "Q16: Is delay determined  by  possible delay  in the  previous  station?  (Hint: this is a form ofautocorrelation).\n",
    "<br>\n",
    "<br>\n",
    "Q17: Regress the number of facilities to both the number of daily trains and number of dailytravelers. Do this using two univariate regressions and determine which covariate is theprimary driver for number of facilities, based on the adequate goodness-of-fit measure.\n",
    "<br>\n",
    "<br>\n",
    "Of course, you can already start on other analyses outside the starting questions. Or on the pre-processing of your data in order to solve the other questions.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
